{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-15T19:23:31.710259Z",
     "iopub.status.busy": "2020-09-15T19:23:31.709333Z",
     "iopub.status.idle": "2020-09-15T19:24:27.998093Z",
     "shell.execute_reply": "2020-09-15T19:24:27.998616Z"
    },
    "papermill": {
     "duration": 56.320516,
     "end_time": "2020-09-15T19:24:27.998810",
     "exception": false,
     "start_time": "2020-09-15T19:23:31.678294",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/bird-panns/torchlibrosa-master/torchlibrosa-master\r\n",
      "Building wheels for collected packages: torchlibrosa\r\n",
      "  Building wheel for torchlibrosa (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for torchlibrosa: filename=torchlibrosa-0.0.4-py3-none-any.whl size=8864 sha256=287bfab740eddd9c514ab4282ac9ba272233f61fce31e61610b2812a8f1225d3\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/52/35/08/7a90aa926e1403318b7b36ba5a03ad940bd5002dad343b8c1f\r\n",
      "Successfully built torchlibrosa\r\n",
      "Installing collected packages: torchlibrosa\r\n",
      "Successfully installed torchlibrosa-0.0.4\r\n",
      "Processing /kaggle/input/noisereduce/noisereduce-1.0.1-py3-none-any.whl\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from noisereduce==1.0.1) (1.18.1)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from noisereduce==1.0.1) (4.45.0)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from noisereduce==1.0.1) (3.2.1)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from noisereduce==1.0.1) (1.4.1)\r\n",
      "Requirement already satisfied: librosa in /opt/conda/lib/python3.7/site-packages (from noisereduce==1.0.1) (0.7.2)\r\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->noisereduce==1.0.1) (2.8.1)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->noisereduce==1.0.1) (1.2.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->noisereduce==1.0.1) (0.10.0)\r\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->noisereduce==1.0.1) (2.4.7)\r\n",
      "Requirement already satisfied: joblib>=0.12 in /opt/conda/lib/python3.7/site-packages (from librosa->noisereduce==1.0.1) (0.14.1)\r\n",
      "Requirement already satisfied: numba>=0.43.0 in /opt/conda/lib/python3.7/site-packages (from librosa->noisereduce==1.0.1) (0.48.0)\r\n",
      "Requirement already satisfied: soundfile>=0.9.0 in /opt/conda/lib/python3.7/site-packages (from librosa->noisereduce==1.0.1) (0.10.3.post1)\r\n",
      "Requirement already satisfied: decorator>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from librosa->noisereduce==1.0.1) (4.4.2)\r\n",
      "Requirement already satisfied: resampy>=0.2.2 in /opt/conda/lib/python3.7/site-packages (from librosa->noisereduce==1.0.1) (0.2.2)\r\n",
      "Requirement already satisfied: six>=1.3 in /opt/conda/lib/python3.7/site-packages (from librosa->noisereduce==1.0.1) (1.14.0)\r\n",
      "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from librosa->noisereduce==1.0.1) (0.23.1)\r\n",
      "Requirement already satisfied: audioread>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from librosa->noisereduce==1.0.1) (2.1.8)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from numba>=0.43.0->librosa->noisereduce==1.0.1) (46.1.3.post20200325)\r\n",
      "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /opt/conda/lib/python3.7/site-packages (from numba>=0.43.0->librosa->noisereduce==1.0.1) (0.31.0)\r\n",
      "Requirement already satisfied: cffi>=1.0 in /opt/conda/lib/python3.7/site-packages (from soundfile>=0.9.0->librosa->noisereduce==1.0.1) (1.14.0)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa->noisereduce==1.0.1) (2.1.0)\r\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi>=1.0->soundfile>=0.9.0->librosa->noisereduce==1.0.1) (2.20)\r\n",
      "Installing collected packages: noisereduce\r\n",
      "Successfully installed noisereduce-1.0.1\r\n"
     ]
    }
   ],
   "source": [
    "!pip install ../input/bird-panns/torchlibrosa-master/torchlibrosa-master/\n",
    "!pip install /kaggle/input/noisereduce/noisereduce-1.0.1-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-09-15T19:24:28.067770Z",
     "iopub.status.busy": "2020-09-15T19:24:28.066908Z",
     "iopub.status.idle": "2020-09-15T19:24:31.798005Z",
     "shell.execute_reply": "2020-09-15T19:24:31.800995Z"
    },
    "papermill": {
     "duration": 3.773818,
     "end_time": "2020-09-15T19:24:31.801166",
     "exception": false,
     "start_time": "2020-09-15T19:24:28.027348",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/noisereduce/noisereduce.py:5: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import time\n",
    "import math\n",
    "import shutil\n",
    "import random\n",
    "import warnings\n",
    "import typing as tp\n",
    "from pathlib import Path\n",
    "from contextlib import contextmanager\n",
    "from glob import glob\n",
    "\n",
    "import yaml\n",
    "from joblib import delayed, Parallel\n",
    "\n",
    "import cv2\n",
    "import librosa\n",
    "import audioread\n",
    "import soundfile as sf\n",
    "import noisereduce as nr\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from fastprogress import progress_bar\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Conv2d, Module, Linear, BatchNorm2d, ReLU\n",
    "from torch.nn.modules.utils import _pair\n",
    "import torch.utils.data as data\n",
    "from torchlibrosa.stft import Spectrogram, LogmelFilterBank\n",
    "from torchlibrosa.augmentation import SpecAugmentation\n",
    "#from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "\n",
    "pd.options.display.max_rows = 500\n",
    "pd.options.display.max_columns = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-15T19:24:31.907963Z",
     "iopub.status.busy": "2020-09-15T19:24:31.907073Z",
     "iopub.status.idle": "2020-09-15T19:24:31.913215Z",
     "shell.execute_reply": "2020-09-15T19:24:31.914264Z"
    },
    "papermill": {
     "duration": 0.061261,
     "end_time": "2020-09-15T19:24:31.914424",
     "exception": false,
     "start_time": "2020-09-15T19:24:31.853163",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # type: ignore\n",
    "#     torch.backends.cudnn.deterministic = True  # type: ignore\n",
    "#     torch.backends.cudnn.benchmark = True  # type: ignore\n",
    "    \n",
    "\n",
    "@contextmanager\n",
    "def timer(name: str) -> None:\n",
    "    \"\"\"Timer Util\"\"\"\n",
    "    t0 = time.time()\n",
    "    print(\"[{}] start\".format(name))\n",
    "    yield\n",
    "    print(\"[{}] done in {:.0f} s\".format(name, time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-15T19:24:32.002213Z",
     "iopub.status.busy": "2020-09-15T19:24:31.999552Z",
     "iopub.status.idle": "2020-09-15T19:24:32.003602Z",
     "shell.execute_reply": "2020-09-15T19:24:32.002972Z"
    },
    "papermill": {
     "duration": 0.050273,
     "end_time": "2020-09-15T19:24:32.003728",
     "exception": false,
     "start_time": "2020-09-15T19:24:31.953455",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# logger = get_logger(\"main.log\")\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-15T19:24:32.094280Z",
     "iopub.status.busy": "2020-09-15T19:24:32.093397Z",
     "iopub.status.idle": "2020-09-15T19:24:32.096094Z",
     "shell.execute_reply": "2020-09-15T19:24:32.095612Z"
    },
    "papermill": {
     "duration": 0.050979,
     "end_time": "2020-09-15T19:24:32.096192",
     "exception": false,
     "start_time": "2020-09-15T19:24:32.045213",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SR = 32000\n",
    "ROOT = Path.cwd().parent\n",
    "INPUT_ROOT = ROOT / \"input\"\n",
    "RAW_DATA = INPUT_ROOT / \"birdsong-recognition\"\n",
    "TRAIN_AUDIO_DIR = RAW_DATA / \"train_audio\"\n",
    "# TRAIN_RESAMPLED_AUDIO_DIRS = [\n",
    "#   INPUT_ROOT / \"birdsong-resampled-train-audio-{:0>2}\".format(i)  for i in range(5)\n",
    "# ]\n",
    "TEST_AUDIO_DIR = RAW_DATA / \"test_audio\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-15T19:24:32.175692Z",
     "iopub.status.busy": "2020-09-15T19:24:32.174937Z",
     "iopub.status.idle": "2020-09-15T19:24:32.178230Z",
     "shell.execute_reply": "2020-09-15T19:24:32.178819Z"
    },
    "papermill": {
     "duration": 0.046769,
     "end_time": "2020-09-15T19:24:32.178963",
     "exception": false,
     "start_time": "2020-09-15T19:24:32.132194",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ENVELOPE = 0.02\n",
    "\n",
    "def envelope(y, rate, threshold):\n",
    "    y_mean = maximum_filter1d(np.abs(y), mode=\"constant\", size=rate//20)\n",
    "    mask = [mean > threshold for mean in y_mean]\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-15T19:24:32.260158Z",
     "iopub.status.busy": "2020-09-15T19:24:32.259407Z",
     "iopub.status.idle": "2020-09-15T19:24:32.571367Z",
     "shell.execute_reply": "2020-09-15T19:24:32.570682Z"
    },
    "papermill": {
     "duration": 0.355338,
     "end_time": "2020-09-15T19:24:32.571516",
     "exception": false,
     "start_time": "2020-09-15T19:24:32.216178",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(RAW_DATA / \"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-15T19:24:32.632459Z",
     "iopub.status.busy": "2020-09-15T19:24:32.631849Z",
     "iopub.status.idle": "2020-09-15T19:24:32.640527Z",
     "shell.execute_reply": "2020-09-15T19:24:32.640007Z"
    },
    "papermill": {
     "duration": 0.041264,
     "end_time": "2020-09-15T19:24:32.640634",
     "exception": false,
     "start_time": "2020-09-15T19:24:32.599370",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not TEST_AUDIO_DIR.exists():\n",
    "    TEST_AUDIO_DIR = INPUT_ROOT / \"birdcall-check\" / \"test_audio\"\n",
    "    test = pd.read_csv(INPUT_ROOT / \"birdcall-check\" / \"test.csv\")\n",
    "else:\n",
    "    test = pd.read_csv(RAW_DATA / \"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-15T19:24:32.702371Z",
     "iopub.status.busy": "2020-09-15T19:24:32.701471Z",
     "iopub.status.idle": "2020-09-15T19:24:32.864299Z",
     "shell.execute_reply": "2020-09-15T19:24:32.864823Z"
    },
    "papermill": {
     "duration": 0.196282,
     "end_time": "2020-09-15T19:24:32.864990",
     "exception": false,
     "start_time": "2020-09-15T19:24:32.668708",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub = pd.read_csv(\"../input/birdsong-recognition/sample_submission.csv\")\n",
    "sub.to_csv(\"submission.csv\", index=False)  # this will be overwritten if everything goes well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2020-09-15T19:24:32.935849Z",
     "iopub.status.busy": "2020-09-15T19:24:32.925329Z",
     "iopub.status.idle": "2020-09-15T19:24:32.964595Z",
     "shell.execute_reply": "2020-09-15T19:24:32.964040Z"
    },
    "papermill": {
     "duration": 0.070169,
     "end_time": "2020-09-15T19:24:32.964733",
     "exception": false,
     "start_time": "2020-09-15T19:24:32.894564",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BIRD_CODE = {\n",
    "    'aldfly': 0, 'ameavo': 1, 'amebit': 2, 'amecro': 3, 'amegfi': 4,\n",
    "    'amekes': 5, 'amepip': 6, 'amered': 7, 'amerob': 8, 'amewig': 9,\n",
    "    'amewoo': 10, 'amtspa': 11, 'annhum': 12, 'astfly': 13, 'baisan': 14,\n",
    "    'baleag': 15, 'balori': 16, 'banswa': 17, 'barswa': 18, 'bawwar': 19,\n",
    "    'belkin1': 20, 'belspa2': 21, 'bewwre': 22, 'bkbcuc': 23, 'bkbmag1': 24,\n",
    "    'bkbwar': 25, 'bkcchi': 26, 'bkchum': 27, 'bkhgro': 28, 'bkpwar': 29,\n",
    "    'bktspa': 30, 'blkpho': 31, 'blugrb1': 32, 'blujay': 33, 'bnhcow': 34,\n",
    "    'boboli': 35, 'bongul': 36, 'brdowl': 37, 'brebla': 38, 'brespa': 39,\n",
    "    'brncre': 40, 'brnthr': 41, 'brthum': 42, 'brwhaw': 43, 'btbwar': 44,\n",
    "    'btnwar': 45, 'btywar': 46, 'buffle': 47, 'buggna': 48, 'buhvir': 49,\n",
    "    'bulori': 50, 'bushti': 51, 'buwtea': 52, 'buwwar': 53, 'cacwre': 54,\n",
    "    'calgul': 55, 'calqua': 56, 'camwar': 57, 'cangoo': 58, 'canwar': 59,\n",
    "    'canwre': 60, 'carwre': 61, 'casfin': 62, 'caster1': 63, 'casvir': 64,\n",
    "    'cedwax': 65, 'chispa': 66, 'chiswi': 67, 'chswar': 68, 'chukar': 69,\n",
    "    'clanut': 70, 'cliswa': 71, 'comgol': 72, 'comgra': 73, 'comloo': 74,\n",
    "    'commer': 75, 'comnig': 76, 'comrav': 77, 'comred': 78, 'comter': 79,\n",
    "    'comyel': 80, 'coohaw': 81, 'coshum': 82, 'cowscj1': 83, 'daejun': 84,\n",
    "    'doccor': 85, 'dowwoo': 86, 'dusfly': 87, 'eargre': 88, 'easblu': 89,\n",
    "    'easkin': 90, 'easmea': 91, 'easpho': 92, 'eastow': 93, 'eawpew': 94,\n",
    "    'eucdov': 95, 'eursta': 96, 'evegro': 97, 'fiespa': 98, 'fiscro': 99,\n",
    "    'foxspa': 100, 'gadwal': 101, 'gcrfin': 102, 'gnttow': 103, 'gnwtea': 104,\n",
    "    'gockin': 105, 'gocspa': 106, 'goleag': 107, 'grbher3': 108, 'grcfly': 109,\n",
    "    'greegr': 110, 'greroa': 111, 'greyel': 112, 'grhowl': 113, 'grnher': 114,\n",
    "    'grtgra': 115, 'grycat': 116, 'gryfly': 117, 'haiwoo': 118, 'hamfly': 119,\n",
    "    'hergul': 120, 'herthr': 121, 'hoomer': 122, 'hoowar': 123, 'horgre': 124,\n",
    "    'horlar': 125, 'houfin': 126, 'houspa': 127, 'houwre': 128, 'indbun': 129,\n",
    "    'juntit1': 130, 'killde': 131, 'labwoo': 132, 'larspa': 133, 'lazbun': 134,\n",
    "    'leabit': 135, 'leafly': 136, 'leasan': 137, 'lecthr': 138, 'lesgol': 139,\n",
    "    'lesnig': 140, 'lesyel': 141, 'lewwoo': 142, 'linspa': 143, 'lobcur': 144,\n",
    "    'lobdow': 145, 'logshr': 146, 'lotduc': 147, 'louwat': 148, 'macwar': 149,\n",
    "    'magwar': 150, 'mallar3': 151, 'marwre': 152, 'merlin': 153, 'moublu': 154,\n",
    "    'mouchi': 155, 'moudov': 156, 'norcar': 157, 'norfli': 158, 'norhar2': 159,\n",
    "    'normoc': 160, 'norpar': 161, 'norpin': 162, 'norsho': 163, 'norwat': 164,\n",
    "    'nrwswa': 165, 'nutwoo': 166, 'olsfly': 167, 'orcwar': 168, 'osprey': 169,\n",
    "    'ovenbi1': 170, 'palwar': 171, 'pasfly': 172, 'pecsan': 173, 'perfal': 174,\n",
    "    'phaino': 175, 'pibgre': 176, 'pilwoo': 177, 'pingro': 178, 'pinjay': 179,\n",
    "    'pinsis': 180, 'pinwar': 181, 'plsvir': 182, 'prawar': 183, 'purfin': 184,\n",
    "    'pygnut': 185, 'rebmer': 186, 'rebnut': 187, 'rebsap': 188, 'rebwoo': 189,\n",
    "    'redcro': 190, 'redhea': 191, 'reevir1': 192, 'renpha': 193, 'reshaw': 194,\n",
    "    'rethaw': 195, 'rewbla': 196, 'ribgul': 197, 'rinduc': 198, 'robgro': 199,\n",
    "    'rocpig': 200, 'rocwre': 201, 'rthhum': 202, 'ruckin': 203, 'rudduc': 204,\n",
    "    'rufgro': 205, 'rufhum': 206, 'rusbla': 207, 'sagspa1': 208, 'sagthr': 209,\n",
    "    'savspa': 210, 'saypho': 211, 'scatan': 212, 'scoori': 213, 'semplo': 214,\n",
    "    'semsan': 215, 'sheowl': 216, 'shshaw': 217, 'snobun': 218, 'snogoo': 219,\n",
    "    'solsan': 220, 'sonspa': 221, 'sora': 222, 'sposan': 223, 'spotow': 224,\n",
    "    'stejay': 225, 'swahaw': 226, 'swaspa': 227, 'swathr': 228, 'treswa': 229,\n",
    "    'truswa': 230, 'tuftit': 231, 'tunswa': 232, 'veery': 233, 'vesspa': 234,\n",
    "    'vigswa': 235, 'warvir': 236, 'wesblu': 237, 'wesgre': 238, 'weskin': 239,\n",
    "    'wesmea': 240, 'wessan': 241, 'westan': 242, 'wewpew': 243, 'whbnut': 244,\n",
    "    'whcspa': 245, 'whfibi': 246, 'whtspa': 247, 'whtswi': 248, 'wilfly': 249,\n",
    "    'wilsni1': 250, 'wiltur': 251, 'winwre3': 252, 'wlswar': 253, 'wooduc': 254,\n",
    "    'wooscj2': 255, 'woothr': 256, 'y00475': 257, 'yebfly': 258, 'yebsap': 259,\n",
    "    'yehbla': 260, 'yelwar': 261, 'yerwar': 262, 'yetvir': 263\n",
    "}\n",
    "\n",
    "INV_BIRD_CODE = {v: k for k, v in BIRD_CODE.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-15T19:24:33.025909Z",
     "iopub.status.busy": "2020-09-15T19:24:33.025260Z",
     "iopub.status.idle": "2020-09-15T19:24:33.029411Z",
     "shell.execute_reply": "2020-09-15T19:24:33.028926Z"
    },
    "papermill": {
     "duration": 0.037077,
     "end_time": "2020-09-15T19:24:33.029528",
     "exception": false,
     "start_time": "2020-09-15T19:24:32.992451",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class TestDataset(data.Dataset):\n",
    "#     def __init__(self, df: pd.DataFrame, clip: np.ndarray):\n",
    "        \n",
    "#         self.df = df\n",
    "#         self.clip = clip\n",
    "        \n",
    "#     def __len__(self):\n",
    "#         return len(self.df)\n",
    "    \n",
    "#     def __getitem__(self, idx: int):\n",
    "#         SR = 32000\n",
    "#         sample = self.df.loc[idx, :]\n",
    "#         site = sample.site\n",
    "#         row_id = sample.row_id\n",
    "        \n",
    "#         if site == \"site_3\":\n",
    "#             y = self.clip.astype(np.float32)\n",
    "#             len_y = len(y)\n",
    "#             start = 0\n",
    "#             end = SR * 10\n",
    "#             y_all = []\n",
    "#             while len_y > start:\n",
    "#                 y_batch = y[start:end].astype(np.float32)\n",
    "#                 if len(y_batch) != (SR * 10):\n",
    "#                     y_pad = np.zeros(10 * SR, dtype=np.float32)\n",
    "#                     y_pad[:len(y_batch)] = y_batch\n",
    "#                     y_all.append(y_pad)\n",
    "#                     break\n",
    "#                 start = end\n",
    "#                 end = end + SR * 10\n",
    "#                 y_all.append(y_batch)\n",
    "#             y_all = np.asarray(y_all)\n",
    "#             return y_all, row_id, site\n",
    "#         else:\n",
    "#             end_seconds = int(sample.seconds)\n",
    "#             start_seconds = int(end_seconds - 5)\n",
    "            \n",
    "#             start_index = SR * start_seconds\n",
    "#             end_index = SR * end_seconds\n",
    "            \n",
    "#             effective_length = SR * 10\n",
    "            \n",
    "#             y = self.clip[start_index:end_index].astype(np.float32)\n",
    "            \n",
    "#             if len(y) < effective_length:\n",
    "#                 new_wave = np.zeros(effective_length, dtype=y.dtype)\n",
    "#                 start = np.random.randint(effective_length - len(y))\n",
    "#                 new_wave[start:start + len(y)] = y\n",
    "#                 y = new_wave.astype(np.float32)\n",
    "#             elif len(y) > effective_length:\n",
    "#                 start = np.random.randint(len(y) - effective_length)\n",
    "#                 y = y[start:start + effective_length].astype(np.float32)\n",
    "#             else:\n",
    "#                 y= y.astype(np.float32)\n",
    "\n",
    "#         return y, row_id, site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-15T19:24:33.110060Z",
     "iopub.status.busy": "2020-09-15T19:24:33.107419Z",
     "iopub.status.idle": "2020-09-15T19:24:33.113187Z",
     "shell.execute_reply": "2020-09-15T19:24:33.112712Z"
    },
    "papermill": {
     "duration": 0.050349,
     "end_time": "2020-09-15T19:24:33.113287",
     "exception": false,
     "start_time": "2020-09-15T19:24:33.062938",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# with padding sequence as the 5 sec sound\n",
    "\n",
    "class TestDataset(data.Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, clip: np.ndarray):\n",
    "        self.df = df\n",
    "        self.clip = clip\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    def __getitem__(self, idx: int):\n",
    "        SR = 32000\n",
    "        sample = self.df.loc[idx, :]\n",
    "        site = sample.site\n",
    "        row_id = sample.row_id\n",
    "        if site == \"site_3\":\n",
    "            y = self.clip.astype(np.float32)\n",
    "            len_y = len(y)\n",
    "            start = 0\n",
    "            end = SR * 5\n",
    "            y_all = []\n",
    "            while len_y > start:\n",
    "                y_batch = y[start:end].astype(np.float32)\n",
    "                if len(y_batch) != (SR * 5):\n",
    "                    y_pad = np.zeros(5 * SR, dtype=np.float32)\n",
    "                    y_pad[:len(y_batch)] = y_batch\n",
    "                    y_all.append(y_pad)\n",
    "                    break\n",
    "                start = end\n",
    "                end = end + SR * 5\n",
    "                y_all.append(y_batch)\n",
    "            y_all = np.asarray(y_all)\n",
    "            y_all = np.tile(y_all,(2,))\n",
    "            return y_all, row_id, site\n",
    "        else:\n",
    "            end_seconds = int(sample.seconds)\n",
    "            start_seconds = int(end_seconds - 5)\n",
    "            start_index = SR * start_seconds\n",
    "            end_index = SR * end_seconds\n",
    "            y = self.clip[start_index:end_index].astype(np.float32)\n",
    "            y = np.tile(y,(2,))\n",
    "        return y, row_id, site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-15T19:24:33.174907Z",
     "iopub.status.busy": "2020-09-15T19:24:33.174154Z",
     "iopub.status.idle": "2020-09-15T19:24:33.177743Z",
     "shell.execute_reply": "2020-09-15T19:24:33.178190Z"
    },
    "papermill": {
     "duration": 0.037074,
     "end_time": "2020-09-15T19:24:33.178309",
     "exception": false,
     "start_time": "2020-09-15T19:24:33.141235",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# with denoising effect \n",
    "\n",
    "# class TestDataset(data.Dataset):\n",
    "#     def __init__(self, df: pd.DataFrame, clip: np.ndarray):\n",
    "#         self.df = df\n",
    "#         self.clip = clip\n",
    "#     def __len__(self):\n",
    "#         return len(self.df)\n",
    "#     def __getitem__(self, idx: int):\n",
    "#         SR = 32000\n",
    "#         sample = self.df.loc[idx, :]\n",
    "#         site = sample.site\n",
    "#         row_id = sample.row_id\n",
    "#         if site == \"site_3\":\n",
    "#             y = self.clip.astype(np.float32)\n",
    "#             len_y = len(y)\n",
    "#             start = 0\n",
    "#             end = SR * 5\n",
    "#             y_all = []\n",
    "#             while len_y > start:\n",
    "#                 y_batch = y[start:end].astype(np.float32)\n",
    "#                 if len(y_batch) != (SR * 5):\n",
    "#                     y_pad = np.zeros(5 * SR, dtype=np.float32)\n",
    "#                     y_pad[:len(y_batch)] = y_batch\n",
    "#                     y_all.append(y_pad)\n",
    "#                     break\n",
    "#                 start = end\n",
    "#                 end = end + SR * 5\n",
    "                \n",
    "#                 # Denoise\n",
    "#                 _y_batch = y_batch[:SR*2]\n",
    "#                 mask = envelope(_y_batch, SR, threshold=ENVELOPE)\n",
    "#                 noise_clip = _y_batch[np.logical_not(mask)]\n",
    "#                 if len(noise_clip):  # noise is exist\n",
    "#                     x_denoise = nr.reduce_noise(y_batch, noise_clip)\n",
    "#                     y_batch = x_denoise\n",
    "                \n",
    "#                 y_all.append(y_batch)\n",
    "#             y_all = np.asarray(y_all)\n",
    "#             y_all = np.tile(y_all,(2,))\n",
    "#             return y_all, row_id, site\n",
    "#         else:\n",
    "#             end_seconds = int(sample.seconds)\n",
    "#             start_seconds = int(end_seconds - 5)\n",
    "#             start_index = SR * start_seconds\n",
    "#             end_index = SR * end_seconds\n",
    "#             y = self.clip[start_index:end_index].astype(np.float32)\n",
    "            \n",
    "#             # denoise\n",
    "#             _y = y[:SR*2]\n",
    "#             mask = envelope(_y, SR, threshold=ENVELOPE)\n",
    "#             noise_clip = _y[np.logical_not(mask)]\n",
    "#             if len(noise_clip):  # noise is exist\n",
    "#                 x_denoise = nr.reduce_noise(y, noise_clip)\n",
    "#                 y = x_denoise\n",
    "            \n",
    "#             y = np.tile(y,(2,))\n",
    "#         return y, row_id, site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2020-09-15T19:24:33.259010Z",
     "iopub.status.busy": "2020-09-15T19:24:33.253605Z",
     "iopub.status.idle": "2020-09-15T19:24:33.317230Z",
     "shell.execute_reply": "2020-09-15T19:24:33.316735Z"
    },
    "papermill": {
     "duration": 0.110552,
     "end_time": "2020-09-15T19:24:33.317343",
     "exception": false,
     "start_time": "2020-09-15T19:24:33.206791",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def init_layer(layer):\n",
    "    \"\"\"Initialize a Linear or Convolutional layer. \"\"\"\n",
    "    nn.init.xavier_uniform_(layer.weight)\n",
    " \n",
    "    if hasattr(layer, 'bias'):\n",
    "        if layer.bias is not None:\n",
    "            layer.bias.data.fill_(0.)\n",
    "            \n",
    "    \n",
    "def init_bn(bn):\n",
    "    \"\"\"Initialize a Batchnorm layer. \"\"\"\n",
    "    bn.bias.data.fill_(0.)\n",
    "    bn.weight.data.fill_(1.)\n",
    "def _resnet_conv3x3(in_planes, out_planes):\n",
    "    #3x3 convolution with padding\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=1,\n",
    "                     padding=1, groups=1, bias=False, dilation=1)\n",
    "\n",
    "\n",
    "def _resnet_conv1x1(in_planes, out_planes):\n",
    "    #1x1 convolution\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=1, bias=False)\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        \n",
    "        super(ConvBlock, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channels, \n",
    "                              out_channels=out_channels,\n",
    "                              kernel_size=(3, 3), stride=(1, 1),\n",
    "                              padding=(1, 1), bias=False)\n",
    "                              \n",
    "        self.conv2 = nn.Conv2d(in_channels=out_channels, \n",
    "                              out_channels=out_channels,\n",
    "                              kernel_size=(3, 3), stride=(1, 1),\n",
    "                              padding=(1, 1), bias=False)\n",
    "                              \n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.init_weight()\n",
    "        \n",
    "    def init_weight(self):\n",
    "        init_layer(self.conv1)\n",
    "        init_layer(self.conv2)\n",
    "        init_bn(self.bn1)\n",
    "        init_bn(self.bn2)\n",
    "\n",
    "        \n",
    "    def forward(self, input, pool_size=(2, 2), pool_type='avg'):\n",
    "        \n",
    "        x = input\n",
    "        x = F.relu_(self.bn1(self.conv1(x)))\n",
    "        x = F.relu_(self.bn2(self.conv2(x)))\n",
    "        if pool_type == 'max':\n",
    "            x = F.max_pool2d(x, kernel_size=pool_size)\n",
    "        elif pool_type == 'avg':\n",
    "            x = F.avg_pool2d(x, kernel_size=pool_size)\n",
    "        elif pool_type == 'avg+max':\n",
    "            x1 = F.avg_pool2d(x, kernel_size=pool_size)\n",
    "            x2 = F.max_pool2d(x, kernel_size=pool_size)\n",
    "            x = x1 + x2\n",
    "        else:\n",
    "            raise Exception('Incorrect argument!')\n",
    "        \n",
    "        return x\n",
    "class _ResnetBasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
    "                 base_width=64, dilation=1, norm_layer=None):\n",
    "        super(_ResnetBasicBlock, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        if groups != 1 or base_width != 64:\n",
    "            raise ValueError('_ResnetBasicBlock only supports groups=1 and base_width=64')\n",
    "        if dilation > 1:\n",
    "            raise NotImplementedError(\"Dilation > 1 not supported in _ResnetBasicBlock\")\n",
    "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
    "\n",
    "        self.stride = stride\n",
    "\n",
    "        self.conv1 = _resnet_conv3x3(inplanes, planes)\n",
    "        self.bn1 = norm_layer(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = _resnet_conv3x3(planes, planes)\n",
    "        self.bn2 = norm_layer(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        init_layer(self.conv1)\n",
    "        init_bn(self.bn1)\n",
    "        init_layer(self.conv2)\n",
    "        init_bn(self.bn2)\n",
    "        nn.init.constant_(self.bn2.weight, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        if self.stride == 2:\n",
    "            out = F.avg_pool2d(x, kernel_size=(2, 2))\n",
    "        else:\n",
    "            out = x\n",
    "\n",
    "        out = self.conv1(out)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = F.dropout(out, p=0.1, training=self.training)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        \n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(identity)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class _ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, zero_init_residual=False,\n",
    "                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n",
    "                 norm_layer=None):\n",
    "        super(_ResNet, self).__init__()\n",
    "\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        self._norm_layer = norm_layer\n",
    "\n",
    "        self.inplanes = 64\n",
    "        self.dilation = 1\n",
    "        if replace_stride_with_dilation is None:\n",
    "            # each element in the tuple indicates if we should replace\n",
    "            # the 2x2 stride with a dilated convolution instead\n",
    "            replace_stride_with_dilation = [False, False, False]\n",
    "        if len(replace_stride_with_dilation) != 3:\n",
    "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
    "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
    "        self.groups = groups\n",
    "        self.base_width = width_per_group\n",
    "\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[0])\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[1])\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[2])\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilation\n",
    "        if dilate:\n",
    "            self.dilation *= stride\n",
    "            stride = 1\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            if stride == 1:\n",
    "                downsample = nn.Sequential(\n",
    "                    _resnet_conv1x1(self.inplanes, planes * block.expansion),\n",
    "                    norm_layer(planes * block.expansion),\n",
    "                )\n",
    "                init_layer(downsample[0])\n",
    "                init_bn(downsample[1])\n",
    "            elif stride == 2:\n",
    "                downsample = nn.Sequential(\n",
    "                    nn.AvgPool2d(kernel_size=2), \n",
    "                    _resnet_conv1x1(self.inplanes, planes * block.expansion),\n",
    "                    norm_layer(planes * block.expansion),\n",
    "                )\n",
    "                init_layer(downsample[1])\n",
    "                init_bn(downsample[2])\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
    "                            self.base_width, previous_dilation, norm_layer))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
    "                                base_width=self.base_width, dilation=self.dilation,\n",
    "                                norm_layer=norm_layer))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        return x\n",
    "class ResNet38(nn.Module):\n",
    "    def __init__(self, sample_rate, window_size, hop_size, mel_bins, fmin, fmax, classes_num):\n",
    "        \n",
    "        super(ResNet38, self).__init__()\n",
    "\n",
    "        window = 'hann'\n",
    "        center = True\n",
    "        pad_mode = 'reflect'\n",
    "        ref = 1.0\n",
    "        amin = 1e-10\n",
    "        top_db = None\n",
    "\n",
    "        # Spectrogram extractor\n",
    "        self.spectrogram_extractor = Spectrogram(n_fft=window_size, hop_length=hop_size, \n",
    "            win_length=window_size, window=window, center=center, pad_mode=pad_mode, \n",
    "            freeze_parameters=True)\n",
    "\n",
    "        # Logmel feature extractor\n",
    "        self.logmel_extractor = LogmelFilterBank(sr=sample_rate, n_fft=window_size, \n",
    "            n_mels=mel_bins, fmin=fmin, fmax=fmax, ref=ref, amin=amin, top_db=top_db, \n",
    "            freeze_parameters=True)\n",
    "\n",
    "        # Spec augmenter\n",
    "        self.spec_augmenter = SpecAugmentation(time_drop_width=64, time_stripes_num=2, \n",
    "            freq_drop_width=8, freq_stripes_num=2)\n",
    "\n",
    "        self.bn0 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.conv_block1 = ConvBlock(in_channels=1, out_channels=64)\n",
    "        # self.conv_block2 = ConvBlock(in_channels=64, out_channels=64)\n",
    "\n",
    "        self.resnet = _ResNet(block=_ResnetBasicBlock, layers=[3, 4, 6, 3], zero_init_residual=True)\n",
    "\n",
    "        self.conv_block_after1 = ConvBlock(in_channels=512, out_channels=2048)\n",
    "\n",
    "        self.fc1 = nn.Linear(2048, 2048)\n",
    "        self.fc_audioset = nn.Linear(2048, classes_num, bias=True)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        init_bn(self.bn0)\n",
    "        init_layer(self.fc1)\n",
    "        init_layer(self.fc_audioset)\n",
    "\n",
    "\n",
    "    def forward(self, input, mixup_lambda=None):\n",
    "        \"\"\"\n",
    "        Input: (batch_size, data_length)\"\"\"\n",
    "\n",
    "        x = self.spectrogram_extractor(input)   # (batch_size, 1, time_steps, freq_bins)\n",
    "        x = self.logmel_extractor(x)    # (batch_size, 1, time_steps, mel_bins)\n",
    "        \n",
    "        x = x.transpose(1, 3)\n",
    "        x = self.bn0(x)\n",
    "        x = x.transpose(1, 3)\n",
    "        \n",
    "        if self.training:\n",
    "            x = self.spec_augmenter(x)\n",
    "\n",
    "        # Mixup on spectrogram\n",
    "        if self.training and mixup_lambda is not None:\n",
    "            x = do_mixup(x, mixup_lambda)\n",
    "        \n",
    "        x = self.conv_block1(x, pool_size=(2, 2), pool_type='avg')\n",
    "        x = F.dropout(x, p=0.2, training=self.training, inplace=True)\n",
    "        x = self.resnet(x)\n",
    "        x = F.avg_pool2d(x, kernel_size=(2, 2))\n",
    "        x = F.dropout(x, p=0.2, training=self.training, inplace=True)\n",
    "        x = self.conv_block_after1(x, pool_size=(1, 1), pool_type='avg')\n",
    "        x = F.dropout(x, p=0.2, training=self.training, inplace=True)\n",
    "        x = torch.mean(x, dim=3)\n",
    "        \n",
    "        (x1, _) = torch.max(x, dim=2)\n",
    "        x2 = torch.mean(x, dim=2)\n",
    "        x = x1 + x2\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = F.relu_(self.fc1(x))\n",
    "        embedding = F.dropout(x, p=0.5, training=self.training)\n",
    "        clipwise_output = torch.sigmoid(self.fc_audioset(x))\n",
    "        \n",
    "        output_dict = {'clipwise_output': clipwise_output, 'embedding': embedding}\n",
    "\n",
    "        return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2020-09-15T19:24:33.387295Z",
     "iopub.status.busy": "2020-09-15T19:24:33.376697Z",
     "iopub.status.idle": "2020-09-15T19:24:33.423219Z",
     "shell.execute_reply": "2020-09-15T19:24:33.423723Z"
    },
    "papermill": {
     "duration": 0.078286,
     "end_time": "2020-09-15T19:24:33.423842",
     "exception": false,
     "start_time": "2020-09-15T19:24:33.345556",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ConvPreWavBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        \n",
    "        super(ConvPreWavBlock, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(in_channels=in_channels, \n",
    "                              out_channels=out_channels,\n",
    "                              kernel_size=3, stride=1,\n",
    "                              padding=1, bias=False)\n",
    "                              \n",
    "        self.conv2 = nn.Conv1d(in_channels=out_channels, \n",
    "                              out_channels=out_channels,\n",
    "                              kernel_size=3, stride=1, dilation=2, \n",
    "                              padding=2, bias=False)\n",
    "                              \n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "\n",
    "        self.init_weight()\n",
    "        \n",
    "    def init_weight(self):\n",
    "        init_layer(self.conv1)\n",
    "        init_layer(self.conv2)\n",
    "        init_bn(self.bn1)\n",
    "        init_bn(self.bn2)\n",
    "\n",
    "        \n",
    "    def forward(self, input, pool_size):\n",
    "        \n",
    "        x = input\n",
    "        x = F.relu_(self.bn1(self.conv1(x)))\n",
    "        x = F.relu_(self.bn2(self.conv2(x)))\n",
    "        x = F.max_pool1d(x, kernel_size=pool_size)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "class Wavegram_Logmel_Cnn14(nn.Module):\n",
    "    def __init__(self, sample_rate, window_size, hop_size, mel_bins, fmin, \n",
    "        fmax, classes_num):\n",
    "        \n",
    "        super(Wavegram_Logmel_Cnn14, self).__init__()\n",
    "\n",
    "        window = 'hann'\n",
    "        center = True\n",
    "        pad_mode = 'reflect'\n",
    "        ref = 1.0\n",
    "        amin = 1e-10\n",
    "        top_db = None\n",
    "\n",
    "        self.pre_conv0 = nn.Conv1d(in_channels=1, out_channels=64, kernel_size=11, stride=5, padding=5, bias=False)\n",
    "        self.pre_bn0 = nn.BatchNorm1d(64)\n",
    "        self.pre_block1 = ConvPreWavBlock(64, 64)\n",
    "        self.pre_block2 = ConvPreWavBlock(64, 128)\n",
    "        self.pre_block3 = ConvPreWavBlock(128, 128)\n",
    "        self.pre_block4 = ConvBlock(in_channels=4, out_channels=64)\n",
    "\n",
    "        # Spectrogram extractor\n",
    "        self.spectrogram_extractor = Spectrogram(n_fft=window_size, hop_length=hop_size, \n",
    "            win_length=window_size, window=window, center=center, pad_mode=pad_mode, \n",
    "            freeze_parameters=True)\n",
    "\n",
    "        # Logmel feature extractor\n",
    "        self.logmel_extractor = LogmelFilterBank(sr=sample_rate, n_fft=window_size, \n",
    "            n_mels=mel_bins, fmin=fmin, fmax=fmax, ref=ref, amin=amin, top_db=top_db, \n",
    "            freeze_parameters=True)\n",
    "\n",
    "        # Spec augmenter\n",
    "        self.spec_augmenter = SpecAugmentation(time_drop_width=64, time_stripes_num=2, \n",
    "            freq_drop_width=8, freq_stripes_num=2)\n",
    "\n",
    "        self.bn0 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.conv_block1 = ConvBlock(in_channels=1, out_channels=64)\n",
    "        self.conv_block2 = ConvBlock(in_channels=128, out_channels=128)\n",
    "        self.conv_block3 = ConvBlock(in_channels=128, out_channels=256)\n",
    "        self.conv_block4 = ConvBlock(in_channels=256, out_channels=512)\n",
    "        self.conv_block5 = ConvBlock(in_channels=512, out_channels=1024)\n",
    "        self.conv_block6 = ConvBlock(in_channels=1024, out_channels=2048)\n",
    "\n",
    "        self.fc1 = nn.Linear(2048, 2048, bias=True)\n",
    "        self.fc_audioset = nn.Linear(2048, classes_num, bias=True)\n",
    "        \n",
    "        self.init_weight()\n",
    "\n",
    "    def init_weight(self):\n",
    "        init_layer(self.pre_conv0)\n",
    "        init_bn(self.pre_bn0)\n",
    "        init_bn(self.bn0)\n",
    "        init_layer(self.fc1)\n",
    "        init_layer(self.fc_audioset)\n",
    " \n",
    "    def forward(self, input, mixup_lambda=None):\n",
    "        \"\"\"\n",
    "        Input: (batch_size, data_length)\"\"\"\n",
    "\n",
    "        # Wavegram\n",
    "        a1 = F.relu_(self.pre_bn0(self.pre_conv0(input[:, None, :])))\n",
    "        a1 = self.pre_block1(a1, pool_size=4)\n",
    "        a1 = self.pre_block2(a1, pool_size=4)\n",
    "        a1 = self.pre_block3(a1, pool_size=4)\n",
    "        a1 = a1.reshape((a1.shape[0], -1, 32, a1.shape[-1])).transpose(2, 3)\n",
    "        a1 = self.pre_block4(a1, pool_size=(2, 1))\n",
    "\n",
    "        # Log mel spectrogram\n",
    "        x = self.spectrogram_extractor(input)   # (batch_size, 1, time_steps, freq_bins)\n",
    "        x = self.logmel_extractor(x)    # (batch_size, 1, time_steps, mel_bins)\n",
    "        \n",
    "        x = x.transpose(1, 3)\n",
    "        x = self.bn0(x)\n",
    "        x = x.transpose(1, 3)\n",
    "\n",
    "        if self.training:\n",
    "            x = self.spec_augmenter(x)\n",
    "\n",
    "        # Mixup on spectrogram\n",
    "        if self.training and mixup_lambda is not None:\n",
    "            x = do_mixup(x, mixup_lambda)\n",
    "            a1 = do_mixup(a1, mixup_lambda)\n",
    "        \n",
    "        x = self.conv_block1(x, pool_size=(2, 2), pool_type='avg')\n",
    "\n",
    "        # Concatenate Wavegram and Log mel spectrogram along the channel dimension\n",
    "        x = torch.cat((x, a1), dim=1)\n",
    "\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = self.conv_block2(x, pool_size=(2, 2), pool_type='avg')\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = self.conv_block3(x, pool_size=(2, 2), pool_type='avg')\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = self.conv_block4(x, pool_size=(2, 2), pool_type='avg')\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = self.conv_block5(x, pool_size=(2, 2), pool_type='avg')\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = self.conv_block6(x, pool_size=(1, 1), pool_type='avg')\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = torch.mean(x, dim=3)\n",
    "        \n",
    "        (x1, _) = torch.max(x, dim=2)\n",
    "        x2 = torch.mean(x, dim=2)\n",
    "        x = x1 + x2\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = F.relu_(self.fc1(x))\n",
    "        embedding = F.dropout(x, p=0.5, training=self.training)\n",
    "        clipwise_output = torch.sigmoid(self.fc_audioset(x))\n",
    "        \n",
    "        output_dict = {'clipwise_output': clipwise_output, 'embedding': embedding}\n",
    "\n",
    "        return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-15T19:24:33.489361Z",
     "iopub.status.busy": "2020-09-15T19:24:33.488453Z",
     "iopub.status.idle": "2020-09-15T19:24:33.501878Z",
     "shell.execute_reply": "2020-09-15T19:24:33.502373Z"
    },
    "papermill": {
     "duration": 0.050381,
     "end_time": "2020-09-15T19:24:33.502484",
     "exception": false,
     "start_time": "2020-09-15T19:24:33.452103",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def interpolate(x: torch.Tensor, ratio: int):\n",
    "    \"\"\"Interpolate data in time domain. This is used to compensate the\n",
    "    resolution reduction in downsampling of a CNN.\n",
    "\n",
    "    Args:\n",
    "      x: (batch_size, time_steps, classes_num)\n",
    "      ratio: int, ratio to interpolate\n",
    "    Returns:\n",
    "      upsampled: (batch_size, time_steps * ratio, classes_num)\n",
    "    \"\"\"\n",
    "    (batch_size, time_steps, classes_num) = x.shape\n",
    "    upsampled = x[:, :, None, :].repeat(1, 1, ratio, 1)\n",
    "    upsampled = upsampled.reshape(batch_size, time_steps * ratio, classes_num)\n",
    "    return upsampled\n",
    "\n",
    "\n",
    "def pad_framewise_output(framewise_output: torch.Tensor, frames_num: int):\n",
    "    \"\"\"Pad framewise_output to the same length as input frames. The pad value\n",
    "    is the same as the value of the last frame.\n",
    "    Args:\n",
    "      framewise_output: (batch_size, frames_num, classes_num)\n",
    "      frames_num: int, number of frames to pad\n",
    "    Outputs:\n",
    "      output: (batch_size, frames_num, classes_num)\n",
    "    \"\"\"\n",
    "    pad = framewise_output[:, -1:, :].repeat(\n",
    "        1, frames_num - framewise_output.shape[1], 1)\n",
    "    \"\"\"tensor for padding\"\"\"\n",
    "\n",
    "    output = torch.cat((framewise_output, pad), dim=1)\n",
    "    \"\"\"(batch_size, frames_num, classes_num)\"\"\"\n",
    "\n",
    "    return output\n",
    "\n",
    "class AttBlock(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_features: int,\n",
    "                 out_features: int,\n",
    "                 activation=\"linear\",\n",
    "                 temperature=1.0):\n",
    "        super().__init__()\n",
    "\n",
    "        self.activation = activation\n",
    "        self.temperature = temperature\n",
    "        self.att = nn.Conv1d(\n",
    "            in_channels=in_features,\n",
    "            out_channels=out_features,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=True)\n",
    "        self.cla = nn.Conv1d(\n",
    "            in_channels=in_features,\n",
    "            out_channels=out_features,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=True)\n",
    "\n",
    "        self.bn_att = nn.BatchNorm1d(out_features)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        init_layer(self.att)\n",
    "        init_layer(self.cla)\n",
    "        init_bn(self.bn_att)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (n_samples, n_in, n_time)\n",
    "        norm_att = torch.softmax(torch.clamp(self.att(x), -10, 10), dim=-1)\n",
    "        cla = self.nonlinear_transform(self.cla(x))\n",
    "        x = torch.sum(norm_att * cla, dim=2)\n",
    "        return x, norm_att, cla\n",
    "\n",
    "    def nonlinear_transform(self, x):\n",
    "        if self.activation == 'linear':\n",
    "            return x\n",
    "        elif self.activation == 'sigmoid':\n",
    "            return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-15T19:24:33.576638Z",
     "iopub.status.busy": "2020-09-15T19:24:33.567531Z",
     "iopub.status.idle": "2020-09-15T19:24:33.579374Z",
     "shell.execute_reply": "2020-09-15T19:24:33.578893Z"
    },
    "papermill": {
     "duration": 0.048687,
     "end_time": "2020-09-15T19:24:33.579471",
     "exception": false,
     "start_time": "2020-09-15T19:24:33.530784",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Transfer_Cnn14(nn.Module):\n",
    "    def __init__(self, sample_rate, window_size, hop_size, mel_bins, fmin, fmax, classes_num):\n",
    "        super(Transfer_Cnn14, self).__init__()\n",
    "        audioset_classes_num = 527\n",
    "        \n",
    "        self.base = Wavegram_Logmel_Cnn14(sample_rate, window_size, \n",
    "                                          hop_size, mel_bins, fmin,\n",
    "                                          fmax, audioset_classes_num)\n",
    "\n",
    "        # Transfer to another task layer\n",
    "        self.fc1 = nn.Linear(2048, 2048, bias=True)\n",
    "        self.att_block = AttBlock(2048, classes_num, activation='sigmoid')\n",
    "        self.interpolate_ratio = 32\n",
    "        self.init_weight()\n",
    "    def init_weight(self):\n",
    "        init_layer(self.fc1)\n",
    "        \n",
    "    def load_from_pretrain(self, pretrained_checkpoint_path):\n",
    "        checkpoint = torch.load(pretrained_checkpoint_path)\n",
    "        self.base.load_state_dict(checkpoint['model'])\n",
    "\n",
    "    def forward(self, input, mixup_lambda=None):\n",
    "        \"\"\"Input: (batch_size, data_length)\n",
    "        \"\"\"\n",
    "        base_output = self.base(input, mixup_lambda)\n",
    "        x = base_output['embedding']\n",
    "        frames_num = base_output['frames_num']\n",
    "        x1 = F.max_pool1d(x, kernel_size=3, stride=1, padding=1)\n",
    "        x2 = F.avg_pool1d(x, kernel_size=3, stride=1, padding=1)\n",
    "        x = x1 + x2\n",
    "\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = x.transpose(1, 2)\n",
    "        x = F.relu_(self.fc1(x))\n",
    "        x = x.transpose(1, 2)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        (clipwise_output, norm_att, segmentwise_output) = self.att_block(x)\n",
    "        segmentwise_output = segmentwise_output.transpose(1, 2)\n",
    "\n",
    "        # Get framewise output\n",
    "        framewise_output = interpolate(segmentwise_output,\n",
    "                                       self.interpolate_ratio)\n",
    "        framewise_output = pad_framewise_output(framewise_output, frames_num)\n",
    "\n",
    "        output_dict = {\n",
    "            'framewise_output': framewise_output,\n",
    "            'clipwise_output': clipwise_output\n",
    "        }\n",
    "\n",
    "        return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-15T19:24:33.671330Z",
     "iopub.status.busy": "2020-09-15T19:24:33.649932Z",
     "iopub.status.idle": "2020-09-15T19:24:33.684739Z",
     "shell.execute_reply": "2020-09-15T19:24:33.685245Z"
    },
    "papermill": {
     "duration": 0.077098,
     "end_time": "2020-09-15T19:24:33.685358",
     "exception": false,
     "start_time": "2020-09-15T19:24:33.608260",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def init_layer(layer):\n",
    "    \"\"\"Initialize a Linear or Convolutional layer. \"\"\"\n",
    "    nn.init.xavier_uniform_(layer.weight)\n",
    " \n",
    "    if hasattr(layer, 'bias'):\n",
    "        if layer.bias is not None:\n",
    "            layer.bias.data.fill_(0.)\n",
    "            \n",
    "    \n",
    "def init_bn(bn):\n",
    "    \"\"\"Initialize a Batchnorm layer. \"\"\"\n",
    "    bn.bias.data.fill_(0.)\n",
    "    bn.weight.data.fill_(1.)\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        \n",
    "        super(ConvBlock, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channels, \n",
    "                              out_channels=out_channels,\n",
    "                              kernel_size=(3, 3), stride=(1, 1),\n",
    "                              padding=(1, 1), bias=False)\n",
    "                              \n",
    "        self.conv2 = nn.Conv2d(in_channels=out_channels, \n",
    "                              out_channels=out_channels,\n",
    "                              kernel_size=(3, 3), stride=(1, 1),\n",
    "                              padding=(1, 1), bias=False)\n",
    "                              \n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.init_weight()\n",
    "        \n",
    "    def init_weight(self):\n",
    "        init_layer(self.conv1)\n",
    "        init_layer(self.conv2)\n",
    "        init_bn(self.bn1)\n",
    "        init_bn(self.bn2)\n",
    "\n",
    "        \n",
    "    def forward(self, input, pool_size=(2, 2), pool_type='avg'):\n",
    "        \n",
    "        x = input\n",
    "        x = F.relu_(self.bn1(self.conv1(x)))\n",
    "        x = F.relu_(self.bn2(self.conv2(x)))\n",
    "        if pool_type == 'max':\n",
    "            x = F.max_pool2d(x, kernel_size=pool_size)\n",
    "        elif pool_type == 'avg':\n",
    "            x = F.avg_pool2d(x, kernel_size=pool_size)\n",
    "        elif pool_type == 'avg+max':\n",
    "            x1 = F.avg_pool2d(x, kernel_size=pool_size)\n",
    "            x2 = F.max_pool2d(x, kernel_size=pool_size)\n",
    "            x = x1 + x2\n",
    "        else:\n",
    "            raise Exception('Incorrect argument!')\n",
    "        \n",
    "        return x\n",
    "    \n",
    "class Cnn14(nn.Module):\n",
    "    def __init__(self, sample_rate, window_size, hop_size, mel_bins, fmin, \n",
    "        fmax, classes_num):\n",
    "        \n",
    "        super(Cnn14, self).__init__()\n",
    "\n",
    "        window = 'hann'\n",
    "        center = True\n",
    "        pad_mode = 'reflect'\n",
    "        ref = 1.0\n",
    "        amin = 1e-10\n",
    "        top_db = None\n",
    "\n",
    "        # Spectrogram extractor\n",
    "        self.spectrogram_extractor = Spectrogram(n_fft=window_size, hop_length=hop_size, \n",
    "            win_length=window_size, window=window, center=center, pad_mode=pad_mode, \n",
    "            freeze_parameters=True)\n",
    "\n",
    "        # Logmel feature extractor\n",
    "        self.logmel_extractor = LogmelFilterBank(sr=sample_rate, n_fft=window_size, \n",
    "            n_mels=mel_bins, fmin=fmin, fmax=fmax, ref=ref, amin=amin, top_db=top_db, \n",
    "            freeze_parameters=True)\n",
    "\n",
    "        # Spec augmenter\n",
    "        self.spec_augmenter = SpecAugmentation(time_drop_width=64, time_stripes_num=2, \n",
    "            freq_drop_width=8, freq_stripes_num=2)\n",
    "\n",
    "        self.bn0 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.conv_block1 = ConvBlock(in_channels=1, out_channels=64)\n",
    "        self.conv_block2 = ConvBlock(in_channels=64, out_channels=128)\n",
    "        self.conv_block3 = ConvBlock(in_channels=128, out_channels=256)\n",
    "        self.conv_block4 = ConvBlock(in_channels=256, out_channels=512)\n",
    "        self.conv_block5 = ConvBlock(in_channels=512, out_channels=1024)\n",
    "        self.conv_block6 = ConvBlock(in_channels=1024, out_channels=2048)\n",
    "\n",
    "        self.fc1 = nn.Linear(2048, 2048, bias=True)\n",
    "        self.fc_audioset = nn.Linear(2048, classes_num, bias=True)\n",
    "        \n",
    "        self.init_weight()\n",
    "\n",
    "    def init_weight(self):\n",
    "        init_bn(self.bn0)\n",
    "        init_layer(self.fc1)\n",
    "        init_layer(self.fc_audioset)\n",
    " \n",
    "    def forward(self, input, mixup_lambda=None):\n",
    "        \"\"\"\n",
    "        Input: (batch_size, data_length)\"\"\"\n",
    "\n",
    "        x = self.spectrogram_extractor(input)   # (batch_size, 1, time_steps, freq_bins)\n",
    "        x = self.logmel_extractor(x)    # (batch_size, 1, time_steps, mel_bins)\n",
    "\n",
    "        x = x.transpose(1, 3)\n",
    "        x = self.bn0(x)\n",
    "        x = x.transpose(1, 3)\n",
    "        \n",
    "        if self.training:\n",
    "            x = self.spec_augmenter(x)\n",
    "\n",
    "        # Mixup on spectrogram\n",
    "        if self.training and mixup_lambda is not None:\n",
    "            x = do_mixup(x, mixup_lambda)\n",
    "\n",
    "        x = self.conv_block1(x, pool_size=(2, 2), pool_type='avg')\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = self.conv_block2(x, pool_size=(2, 2), pool_type='avg')\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = self.conv_block3(x, pool_size=(2, 2), pool_type='avg')\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = self.conv_block4(x, pool_size=(2, 2), pool_type='avg')\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = self.conv_block5(x, pool_size=(2, 2), pool_type='avg')\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = self.conv_block6(x, pool_size=(1, 1), pool_type='avg')\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = torch.mean(x, dim=3)\n",
    "        \n",
    "        (x1, _) = torch.max(x, dim=2)\n",
    "        x2 = torch.mean(x, dim=2)\n",
    "        x = x1 + x2\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = F.relu_(self.fc1(x))\n",
    "        embedding = F.dropout(x, p=0.5, training=self.training)\n",
    "        clipwise_output = torch.sigmoid(self.fc_audioset(x))\n",
    "        \n",
    "        output_dict = {'clipwise_output': clipwise_output, 'embedding': embedding}\n",
    "\n",
    "        return output_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-15T19:24:33.752844Z",
     "iopub.status.busy": "2020-09-15T19:24:33.751066Z",
     "iopub.status.idle": "2020-09-15T19:24:33.753528Z",
     "shell.execute_reply": "2020-09-15T19:24:33.754011Z"
    },
    "papermill": {
     "duration": 0.039795,
     "end_time": "2020-09-15T19:24:33.754125",
     "exception": false,
     "start_time": "2020-09-15T19:24:33.714330",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_model(weight_path=None):\n",
    "    \n",
    "    model_config = {\n",
    "        \"sample_rate\": 32000,\n",
    "        \"window_size\": 1024,\n",
    "        \"hop_size\": 320,\n",
    "        \"mel_bins\": 64,\n",
    "        \"fmin\": 50,\n",
    "        \"fmax\": 14000,\n",
    "        \"classes_num\":264\n",
    "        }\n",
    "\n",
    "    model = ResNet38(**model_config)\n",
    "    # model.fc_audioset = nn.Linear(2048, num_classes, bias=True)\n",
    "    # init_layer(model.fc_audioset)\n",
    "    if weight_path:\n",
    "        print(\"load pretrain weight: {}\".format(weight_path))\n",
    "        weights = torch.load(weight_path, map_location=torch.device('cpu'))\n",
    "        model.load_state_dict(weights['model_state_dict'])\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-15T19:24:33.820826Z",
     "iopub.status.busy": "2020-09-15T19:24:33.819021Z",
     "iopub.status.idle": "2020-09-15T19:24:33.821531Z",
     "shell.execute_reply": "2020-09-15T19:24:33.822013Z"
    },
    "papermill": {
     "duration": 0.039206,
     "end_time": "2020-09-15T19:24:33.822121",
     "exception": false,
     "start_time": "2020-09-15T19:24:33.782915",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_model_cnn14(weight_path=None):\n",
    "    \n",
    "    model_config = {\n",
    "        \"sample_rate\": 32000,\n",
    "        \"window_size\": 1024,\n",
    "        \"hop_size\": 320,\n",
    "        \"mel_bins\": 64,\n",
    "        \"fmin\": 50,\n",
    "        \"fmax\": 14000,\n",
    "        \"classes_num\":264\n",
    "        }\n",
    "\n",
    "    model = Cnn14(**model_config)\n",
    "    # model.fc_audioset = nn.Linear(2048, num_classes, bias=True)\n",
    "    # init_layer(model.fc_audioset)\n",
    "    if weight_path:\n",
    "        print(\"load pretrain weight: {}\".format(weight_path))\n",
    "        weights = torch.load(weight_path, map_location=torch.device('cpu'))\n",
    "        model.load_state_dict(weights['model_state_dict'])\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-15T19:24:33.887398Z",
     "iopub.status.busy": "2020-09-15T19:24:33.886795Z",
     "iopub.status.idle": "2020-09-15T19:24:33.891233Z",
     "shell.execute_reply": "2020-09-15T19:24:33.890740Z"
    },
    "papermill": {
     "duration": 0.040407,
     "end_time": "2020-09-15T19:24:33.891321",
     "exception": false,
     "start_time": "2020-09-15T19:24:33.850914",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_model_wavegram(weight_path=None):\n",
    "    \n",
    "    model_config = {\n",
    "        \"sample_rate\": 32000,\n",
    "        \"window_size\": 1024,\n",
    "        \"hop_size\": 320,\n",
    "        \"mel_bins\": 64,\n",
    "        \"fmin\": 50,\n",
    "        \"fmax\": 14000,\n",
    "        \"classes_num\":264\n",
    "        }\n",
    "\n",
    "    model = Wavegram_Logmel_Cnn14(**model_config)\n",
    "    if weight_path:\n",
    "        print(\"load pretrain weight: {}\".format(weight_path))\n",
    "        weights = torch.load(weight_path, map_location=torch.device('cpu'))\n",
    "        model.load_state_dict(weights['model_state_dict'])\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.029214,
     "end_time": "2020-09-15T19:24:33.949764",
     "exception": false,
     "start_time": "2020-09-15T19:24:33.920550",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Prediction loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2020-09-15T19:24:34.036589Z",
     "iopub.status.busy": "2020-09-15T19:24:34.026057Z",
     "iopub.status.idle": "2020-09-15T19:24:34.069051Z",
     "shell.execute_reply": "2020-09-15T19:24:34.068563Z"
    },
    "papermill": {
     "duration": 0.090302,
     "end_time": "2020-09-15T19:24:34.069146",
     "exception": false,
     "start_time": "2020-09-15T19:24:33.978844",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prediction_for_clip(test_df: pd.DataFrame, \n",
    "                        clip: np.ndarray, \n",
    "                        models, \n",
    "                        threshold=0.5):\n",
    "\n",
    "    dataset = TestDataset(df=test_df, \n",
    "    clip=clip)\n",
    "    loader = data.DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    models[0].eval()\n",
    "    models[1].eval()\n",
    "    models[2].eval()\n",
    "    models[3].eval()\n",
    "    models[4].eval()\n",
    "    models[5].eval()\n",
    "    models[6].eval()\n",
    "    models[7].eval()\n",
    "    models[8].eval()\n",
    "    models[9].eval()\n",
    "    models[10].eval()\n",
    "    models[11].eval()\n",
    "    models[12].eval()\n",
    "    models[13].eval()\n",
    "    models[14].eval()\n",
    "     \n",
    "        \n",
    "    prediction_dict = {}\n",
    "    for image, row_id, site in progress_bar(loader):\n",
    "        site = site[0]\n",
    "        row_id = row_id[0]\n",
    "        image = image.to(device).float()\n",
    "        if site in {\"site_1\", \"site_2\"}:\n",
    "            image = image.to(device).float()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                prediction1 = models[0](image)\n",
    "                proba1 = prediction1['clipwise_output'].detach().cpu().numpy().reshape(-1)\n",
    "                \n",
    "                prediction2 = models[1](image)\n",
    "                proba2 = prediction2['clipwise_output'].detach().cpu().numpy().reshape(-1)\n",
    "                \n",
    "                prediction3 = models[2](image)\n",
    "                proba3 = prediction3['clipwise_output'].detach().cpu().numpy().reshape(-1)\n",
    "                \n",
    "                prediction4 = models[3](image)\n",
    "                proba4 = prediction4['clipwise_output'].detach().cpu().numpy().reshape(-1)\n",
    "                \n",
    "                prediction5 = models[4](image)\n",
    "                proba5 = prediction5['clipwise_output'].detach().cpu().numpy().reshape(-1)\n",
    "                \n",
    "                prediction6 = models[5](image)\n",
    "                proba6 = prediction6['clipwise_output'].detach().cpu().numpy().reshape(-1)\n",
    "                \n",
    "                prediction7 = models[6](image)\n",
    "                proba7 = prediction7['clipwise_output'].detach().cpu().numpy().reshape(-1)\n",
    "                \n",
    "                prediction8 = models[7](image)\n",
    "                proba8 = prediction8['clipwise_output'].detach().cpu().numpy().reshape(-1)\n",
    "                \n",
    "                prediction9 = models[8](image)\n",
    "                proba9 = prediction9['clipwise_output'].detach().cpu().numpy().reshape(-1)\n",
    "                \n",
    "                prediction10 = models[9](image)\n",
    "                proba10 = prediction10['clipwise_output'].detach().cpu().numpy().reshape(-1)\n",
    "                \n",
    "                prediction11 = models[10](image)\n",
    "                proba11 = prediction11['clipwise_output'].detach().cpu().numpy().reshape(-1)\n",
    "                \n",
    "                prediction12 = models[11](image)\n",
    "                proba12 = prediction12['clipwise_output'].detach().cpu().numpy().reshape(-1)\n",
    "                \n",
    "                prediction13 = models[12](image)\n",
    "                proba13 = prediction13['clipwise_output'].detach().cpu().numpy().reshape(-1)\n",
    "                \n",
    "                prediction14 = models[13](image)\n",
    "                proba14 = prediction14['clipwise_output'].detach().cpu().numpy().reshape(-1)\n",
    "                \n",
    "                prediction15 = models[14](image)\n",
    "                proba15 = prediction15['clipwise_output'].detach().cpu().numpy().reshape(-1)\n",
    "                \n",
    "                \n",
    "                \n",
    "            proba = (proba1*0.045+proba2*0.05 +proba3*0.12+proba4*0.13+proba5*0.035+proba6*0.09+proba7*0.08+proba8*0.21+proba9*0.19+proba10*0.05)\n",
    "            proba = proba * 0.8 + (proba11*0.2+proba12*0.2 +proba13*0.2+proba14*0.2+proba15*0.2)*0.2\n",
    "            #print(proba.shape, \"for site 1 and 2\")\n",
    "            events = proba >= threshold\n",
    "            #print(len(events), \"for site 1 and 2\")\n",
    "            labels = np.argwhere(events).reshape(-1).tolist()\n",
    "\n",
    "        else:\n",
    "            # to avoid prediction on large batch\n",
    "            image = image.squeeze(0)\n",
    "            batch_size = 16\n",
    "            whole_size = image.size(0)\n",
    "            if whole_size % batch_size == 0:\n",
    "                n_iter = whole_size // batch_size\n",
    "            else:\n",
    "                n_iter = whole_size // batch_size + 1\n",
    "                \n",
    "            all_events = set()\n",
    "            for batch_i in range(n_iter):\n",
    "                batch = image[batch_i * batch_size:(batch_i + 1) * batch_size]\n",
    "                if batch.ndim == 3:\n",
    "                    batch = batch.unsqueeze(0)\n",
    "\n",
    "                batch = batch.to(device)\n",
    "                with torch.no_grad():\n",
    "                    prediction1 = models[0](batch)\n",
    "                    proba1 = prediction1['clipwise_output'].detach().cpu().numpy()\n",
    "                \n",
    "                    prediction2 = models[1](batch)\n",
    "                    proba2 = prediction2['clipwise_output'].detach().cpu().numpy()\n",
    "                \n",
    "                    prediction3 = models[2](batch)\n",
    "                    proba3 = prediction3['clipwise_output'].detach().cpu().numpy()\n",
    "                \n",
    "                    prediction4 = models[3](batch)\n",
    "                    proba4 = prediction4['clipwise_output'].detach().cpu().numpy()\n",
    "                    \n",
    "                    prediction5 = models[4](batch)\n",
    "                    proba5 = prediction5['clipwise_output'].detach().cpu().numpy()\n",
    "                    \n",
    "                    prediction6 = models[5](batch)\n",
    "                    proba6 = prediction6['clipwise_output'].detach().cpu().numpy()\n",
    "                    \n",
    "                    prediction7 = models[6](batch)\n",
    "                    proba7 = prediction7['clipwise_output'].detach().cpu().numpy()\n",
    "                    \n",
    "                    prediction8 = models[7](batch)\n",
    "                    proba8 = prediction8['clipwise_output'].detach().cpu().numpy()\n",
    "                    \n",
    "                    prediction9 = models[8](batch)\n",
    "                    proba9 = prediction9['clipwise_output'].detach().cpu().numpy()\n",
    "                    \n",
    "                    prediction10 = models[9](batch)\n",
    "                    proba10 = prediction10['clipwise_output'].detach().cpu().numpy()\n",
    "                    \n",
    "                    prediction11 = models[10](batch)\n",
    "                    proba11 = prediction11['clipwise_output'].detach().cpu().numpy()\n",
    "                    \n",
    "                    prediction12 = models[11](batch)\n",
    "                    proba12 = prediction12['clipwise_output'].detach().cpu().numpy()\n",
    "                    \n",
    "                    prediction13 = models[12](batch)\n",
    "                    proba13 = prediction13['clipwise_output'].detach().cpu().numpy()\n",
    "                    \n",
    "                    prediction14 = models[13](batch)\n",
    "                    proba14 = prediction14['clipwise_output'].detach().cpu().numpy()\n",
    "                    \n",
    "                    prediction15 = models[14](batch)\n",
    "                    proba15 = prediction15['clipwise_output'].detach().cpu().numpy()\n",
    "                    \n",
    "                proba = (proba1*0.045+proba2*0.05 +proba3*0.12+proba4*0.13+proba5*0.035+proba6*0.09+proba7*0.08+proba8*0.21+proba9*0.19+proba10*0.05)\n",
    "                proba = proba * 0.8 + (proba11*0.2+proba12*0.2 +proba13*0.2+proba14*0.2+proba15*0.2)*0.2\n",
    "                #print(proba.shape, \"===========\")\n",
    "                events = proba >= 0.3\n",
    "                #print(len(events), \"=========\")\n",
    "                for i in range(len(events)):\n",
    "                    event = events[i, :]\n",
    "                    labels = np.argwhere(event).reshape(-1).tolist()\n",
    "                    for label in labels:\n",
    "                        all_events.add(label)\n",
    "                        \n",
    "            labels = list(all_events)\n",
    "        if len(labels) == 0:\n",
    "            prediction_dict[row_id] = \"nocall\"\n",
    "        else:\n",
    "            labels_str_list = list(map(lambda x: INV_BIRD_CODE[x], labels))\n",
    "            label_string = \" \".join(labels_str_list)\n",
    "            prediction_dict[row_id] = label_string\n",
    "    return prediction_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-15T19:24:34.147967Z",
     "iopub.status.busy": "2020-09-15T19:24:34.140928Z",
     "iopub.status.idle": "2020-09-15T19:24:34.150194Z",
     "shell.execute_reply": "2020-09-15T19:24:34.150705Z"
    },
    "papermill": {
     "duration": 0.052857,
     "end_time": "2020-09-15T19:24:34.150816",
     "exception": false,
     "start_time": "2020-09-15T19:24:34.097959",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prediction(test_df: pd.DataFrame,\n",
    "               test_audio: Path,\n",
    "               weight_path: Path,\n",
    "               target_sr: int,\n",
    "               threshold=0.5):\n",
    "    models_resnets = []\n",
    "    \n",
    "    model1 = get_model(weight_path[0])\n",
    "    models_resnets.append(model1)\n",
    "    model2 = get_model(weight_path[1])\n",
    "    models_resnets.append(model2)\n",
    "    model3 = get_model(weight_path[2])\n",
    "    models_resnets.append(model3)\n",
    "    model4 = get_model(weight_path[3])\n",
    "    models_resnets.append(model4)\n",
    "    model5 = get_model(weight_path[4])\n",
    "    models_resnets.append(model5)\n",
    "    model6 = get_model_cnn14(weight_path[5])\n",
    "    models_resnets.append(model6)\n",
    "    model7 = get_model_cnn14(weight_path[6])\n",
    "    models_resnets.append(model7)\n",
    "    model8 = get_model_cnn14(weight_path[7])\n",
    "    models_resnets.append(model8)\n",
    "    model9 = get_model_cnn14(weight_path[8])\n",
    "    models_resnets.append(model9)\n",
    "    model10 = get_model_cnn14(weight_path[9])\n",
    "    models_resnets.append(model10)\n",
    "    model11 = get_model_wavegram(weight_path[10])\n",
    "    models_resnets.append(model6)\n",
    "    model12 = get_model_wavegram(weight_path[11])\n",
    "    models_resnets.append(model7)\n",
    "    model13 = get_model_wavegram(weight_path[12])\n",
    "    models_resnets.append(model8)\n",
    "    model14 = get_model_wavegram(weight_path[13])\n",
    "    models_resnets.append(model9)\n",
    "    model15 = get_model_wavegram(weight_path[14])\n",
    "    models_resnets.append(model9)\n",
    "    \n",
    "    unique_audio_id = test_df.audio_id.unique()\n",
    "\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    prediction_dfs = []\n",
    "    for audio_id in unique_audio_id:\n",
    "        with timer(f\"Loading {audio_id}\"):\n",
    "            clip, _ = librosa.load(test_audio / (audio_id + \".mp3\"),\n",
    "                                   sr=target_sr,\n",
    "                                   mono=True,\n",
    "                                   res_type=\"kaiser_fast\")\n",
    "        \n",
    "        test_df_for_audio_id = test_df.query(\n",
    "            f\"audio_id == '{audio_id}'\").reset_index(drop=True)\n",
    "        with timer(f\"Prediction on {audio_id}\"):\n",
    "            prediction_dict = prediction_for_clip(test_df_for_audio_id,\n",
    "                                                  clip=clip,\n",
    "                                                  models=models_resnets,\n",
    "                                                  threshold=threshold)\n",
    "        row_id = list(prediction_dict.keys())\n",
    "        birds = list(prediction_dict.values())\n",
    "        prediction_df = pd.DataFrame({\n",
    "            \"row_id\": row_id,\n",
    "            \"birds\": birds\n",
    "        })\n",
    "        prediction_dfs.append(prediction_df)\n",
    "    \n",
    "    prediction_df = pd.concat(prediction_dfs, axis=0, sort=False).reset_index(drop=True)\n",
    "    return prediction_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.028987,
     "end_time": "2020-09-15T19:24:34.209194",
     "exception": false,
     "start_time": "2020-09-15T19:24:34.180207",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2020-09-15T19:24:34.274594Z",
     "iopub.status.busy": "2020-09-15T19:24:34.273949Z",
     "iopub.status.idle": "2020-09-15T19:25:44.573548Z",
     "shell.execute_reply": "2020-09-15T19:25:44.574277Z"
    },
    "papermill": {
     "duration": 70.335417,
     "end_time": "2020-09-15T19:25:44.574512",
     "exception": false,
     "start_time": "2020-09-15T19:24:34.239095",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load pretrain weight: ../input/resnest-38-fold-0-epochs-80/panns/best-acc-checkpoint.bin\n",
      "load pretrain weight: ../input/resnest-38-fold-1-85-epochs/panns/best-acc-checkpoint.bin\n",
      "load pretrain weight: ../input/resnest-38-fold-2-85-epochs/panns/best-acc-checkpoint.bin\n",
      "load pretrain weight: ../input/resnest-38-fold-3-85-epochs/panns/best-acc-checkpoint.bin\n",
      "load pretrain weight: ../input/resnest-38-fold-4-85-epochs/panns/best-acc-checkpoint.bin\n",
      "load pretrain weight: ../input/cnn14-fold-0-80-epochs/panns/best-acc-checkpoint.bin\n",
      "load pretrain weight: ../input/cnn-14-80epochs/best-acc-checkpoint (2).bin\n",
      "load pretrain weight: ../input/cnn14-fold-2/panns/best-acc-checkpoint.bin\n",
      "load pretrain weight: ../input/cnn14-fold3-40-epochs/panns/best-acc-checkpoint.bin\n",
      "load pretrain weight: ../input/cnn14-80epochs-fold4/best-acc-checkpoint.bin\n",
      "load pretrain weight: ../input/wavegram-weights/fold_1.bin\n",
      "load pretrain weight: ../input/wavegram-weights/fold_3.bin\n",
      "load pretrain weight: ../input/wavegram-weights/fold_2.bin\n",
      "load pretrain weight: ../input/wavegram-weights/fold_0.bin\n",
      "load pretrain weight: ../input/wavegram-weights/fold_4.bin\n",
      "[Loading 41e6fe6504a34bf6846938ba78d13df1] start\n",
      "[Loading 41e6fe6504a34bf6846938ba78d13df1] done in 1 s\n",
      "[Prediction on 41e6fe6504a34bf6846938ba78d13df1] start\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='5' class='' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [5/5 00:01<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Prediction on 41e6fe6504a34bf6846938ba78d13df1] done in 2 s\n",
      "[Loading cce64fffafed40f2b2f3d3413ec1c4c2] start\n",
      "[Loading cce64fffafed40f2b2f3d3413ec1c4c2] done in 1 s\n",
      "[Prediction on cce64fffafed40f2b2f3d3413ec1c4c2] start\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='7' class='' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [7/7 00:01<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Prediction on cce64fffafed40f2b2f3d3413ec1c4c2] done in 1 s\n",
      "[Loading 99af324c881246949408c0b1ae54271f] start\n",
      "[Loading 99af324c881246949408c0b1ae54271f] done in 1 s\n",
      "[Prediction on 99af324c881246949408c0b1ae54271f] start\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='7' class='' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [7/7 00:01<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Prediction on 99af324c881246949408c0b1ae54271f] done in 1 s\n",
      "[Loading 6ab74e177aa149468a39ca10beed6222] start\n",
      "[Loading 6ab74e177aa149468a39ca10beed6222] done in 1 s\n",
      "[Prediction on 6ab74e177aa149468a39ca10beed6222] start\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='6' class='' max='6' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [6/6 00:01<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Prediction on 6ab74e177aa149468a39ca10beed6222] done in 1 s\n",
      "[Loading b2fd3f01e9284293a1e33f9c811a2ed6] start\n",
      "[Loading b2fd3f01e9284293a1e33f9c811a2ed6] done in 1 s\n",
      "[Prediction on b2fd3f01e9284293a1e33f9c811a2ed6] start\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='7' class='' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [7/7 00:01<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Prediction on b2fd3f01e9284293a1e33f9c811a2ed6] done in 1 s\n",
      "[Loading de62b37ebba749d2abf29d4a493ea5d4] start\n",
      "[Loading de62b37ebba749d2abf29d4a493ea5d4] done in 0 s\n",
      "[Prediction on de62b37ebba749d2abf29d4a493ea5d4] start\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [1/1 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Prediction on de62b37ebba749d2abf29d4a493ea5d4] done in 0 s\n",
      "[Loading 8680a8dd845d40f296246dbed0d37394] start\n",
      "[Loading 8680a8dd845d40f296246dbed0d37394] done in 1 s\n",
      "[Prediction on 8680a8dd845d40f296246dbed0d37394] start\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='9' class='' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [9/9 00:01<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Prediction on 8680a8dd845d40f296246dbed0d37394] done in 2 s\n",
      "[Loading 940d546e5eb745c9a74bce3f35efa1f9] start\n",
      "[Loading 940d546e5eb745c9a74bce3f35efa1f9] done in 1 s\n",
      "[Prediction on 940d546e5eb745c9a74bce3f35efa1f9] start\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='14' class='' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [14/14 00:02<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Prediction on 940d546e5eb745c9a74bce3f35efa1f9] done in 3 s\n",
      "[Loading 07ab324c602e4afab65ddbcc746c31b5] start\n",
      "[Loading 07ab324c602e4afab65ddbcc746c31b5] done in 1 s\n",
      "[Prediction on 07ab324c602e4afab65ddbcc746c31b5] start\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='5' class='' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [5/5 00:01<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Prediction on 07ab324c602e4afab65ddbcc746c31b5] done in 1 s\n",
      "[Loading 899616723a32409c996f6f3441646c2a] start\n",
      "[Loading 899616723a32409c996f6f3441646c2a] done in 1 s\n",
      "[Prediction on 899616723a32409c996f6f3441646c2a] start\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='10' class='' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [10/10 00:02<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Prediction on 899616723a32409c996f6f3441646c2a] done in 2 s\n",
      "[Loading 9cc5d9646f344f1bbb52640a988fe902] start\n",
      "[Loading 9cc5d9646f344f1bbb52640a988fe902] done in 3 s\n",
      "[Prediction on 9cc5d9646f344f1bbb52640a988fe902] start\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [1/1 00:04<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Prediction on 9cc5d9646f344f1bbb52640a988fe902] done in 4 s\n",
      "[Loading a56e20a518684688a9952add8a9d5213] start\n",
      "[Loading a56e20a518684688a9952add8a9d5213] done in 1 s\n",
      "[Prediction on a56e20a518684688a9952add8a9d5213] start\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [1/1 00:01<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Prediction on a56e20a518684688a9952add8a9d5213] done in 1 s\n",
      "[Loading 96779836288745728306903d54e264dd] start\n",
      "[Loading 96779836288745728306903d54e264dd] done in 0 s\n",
      "[Prediction on 96779836288745728306903d54e264dd] start\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [1/1 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Prediction on 96779836288745728306903d54e264dd] done in 1 s\n",
      "[Loading f77783ba4c6641bc918b034a18c23e53] start\n",
      "[Loading f77783ba4c6641bc918b034a18c23e53] done in 0 s\n",
      "[Prediction on f77783ba4c6641bc918b034a18c23e53] start\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [1/1 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Prediction on f77783ba4c6641bc918b034a18c23e53] done in 0 s\n",
      "[Loading 856b194b097441958697c2bcd1f63982] start\n",
      "[Loading 856b194b097441958697c2bcd1f63982] done in 1 s\n",
      "[Prediction on 856b194b097441958697c2bcd1f63982] start\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [1/1 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Prediction on 856b194b097441958697c2bcd1f63982] done in 1 s\n"
     ]
    }
   ],
   "source": [
    "weights = glob(\"../input/wavegram-weights/*.bin\")\n",
    "\n",
    "submission = prediction(test_df=test,\n",
    "                           test_audio=TEST_AUDIO_DIR,\n",
    "                           weight_path=[\"../input/resnest-38-fold-0-epochs-80/panns/best-acc-checkpoint.bin\",#cv 0.71340\n",
    "                                        \"../input/resnest-38-fold-1-85-epochs/panns/best-acc-checkpoint.bin\",#cv 0.71453\n",
    "                                        \"../input/resnest-38-fold-2-85-epochs/panns/best-acc-checkpoint.bin\",#cv 0.72323\n",
    "                                        \"../input/resnest-38-fold-3-85-epochs/panns/best-acc-checkpoint.bin\",#cv 0.72410\n",
    "                                        \"../input/resnest-38-fold-4-85-epochs/panns/best-acc-checkpoint.bin\",#cv 0.70925\n",
    "                                        \"../input/cnn14-fold-0-80-epochs/panns/best-acc-checkpoint.bin\",# cv 0.72459\n",
    "                                        \"../input/cnn-14-80epochs/best-acc-checkpoint (2).bin\", #cv .721\n",
    "                                        \"../input/cnn14-fold-2/panns/best-acc-checkpoint.bin\",#cv . 0.73896\n",
    "                                        \"../input/cnn14-fold3-40-epochs/panns/best-acc-checkpoint.bin\",#cv . 0.73809,\n",
    "                                        \"../input/cnn14-80epochs-fold4/best-acc-checkpoint.bin\" #cv . 0.71574,\n",
    "                                       ]+weights,\n",
    "                           target_sr=32000,\n",
    "                           threshold=0.56)\n",
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-15T19:25:44.693895Z",
     "iopub.status.busy": "2020-09-15T19:25:44.693224Z",
     "iopub.status.idle": "2020-09-15T19:25:44.709395Z",
     "shell.execute_reply": "2020-09-15T19:25:44.709945Z"
    },
    "papermill": {
     "duration": 0.0805,
     "end_time": "2020-09-15T19:25:44.710065",
     "exception": false,
     "start_time": "2020-09-15T19:25:44.629565",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>birds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>site_1_41e6fe6504a34bf6846938ba78d13df1_5</td>\n",
       "      <td>aldfly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>site_1_41e6fe6504a34bf6846938ba78d13df1_10</td>\n",
       "      <td>aldfly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>site_1_41e6fe6504a34bf6846938ba78d13df1_15</td>\n",
       "      <td>aldfly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>site_1_41e6fe6504a34bf6846938ba78d13df1_20</td>\n",
       "      <td>nocall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>site_1_41e6fe6504a34bf6846938ba78d13df1_25</td>\n",
       "      <td>aldfly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>site_1_cce64fffafed40f2b2f3d3413ec1c4c2_5</td>\n",
       "      <td>aldfly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>site_1_cce64fffafed40f2b2f3d3413ec1c4c2_10</td>\n",
       "      <td>nocall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>site_1_cce64fffafed40f2b2f3d3413ec1c4c2_15</td>\n",
       "      <td>nocall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>site_1_cce64fffafed40f2b2f3d3413ec1c4c2_20</td>\n",
       "      <td>nocall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>site_1_cce64fffafed40f2b2f3d3413ec1c4c2_25</td>\n",
       "      <td>nocall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>site_1_cce64fffafed40f2b2f3d3413ec1c4c2_30</td>\n",
       "      <td>nocall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>site_1_cce64fffafed40f2b2f3d3413ec1c4c2_35</td>\n",
       "      <td>aldfly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>site_1_99af324c881246949408c0b1ae54271f_5</td>\n",
       "      <td>nocall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>site_1_99af324c881246949408c0b1ae54271f_10</td>\n",
       "      <td>aldfly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>site_1_99af324c881246949408c0b1ae54271f_15</td>\n",
       "      <td>nocall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>site_1_99af324c881246949408c0b1ae54271f_20</td>\n",
       "      <td>aldfly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>site_1_99af324c881246949408c0b1ae54271f_25</td>\n",
       "      <td>aldfly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>site_1_99af324c881246949408c0b1ae54271f_30</td>\n",
       "      <td>aldfly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>site_1_99af324c881246949408c0b1ae54271f_35</td>\n",
       "      <td>aldfly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>site_1_6ab74e177aa149468a39ca10beed6222_5</td>\n",
       "      <td>aldfly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>site_1_6ab74e177aa149468a39ca10beed6222_10</td>\n",
       "      <td>aldfly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>site_1_6ab74e177aa149468a39ca10beed6222_15</td>\n",
       "      <td>aldfly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>site_1_6ab74e177aa149468a39ca10beed6222_20</td>\n",
       "      <td>aldfly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>site_1_6ab74e177aa149468a39ca10beed6222_25</td>\n",
       "      <td>aldfly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>site_1_6ab74e177aa149468a39ca10beed6222_30</td>\n",
       "      <td>nocall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>site_1_b2fd3f01e9284293a1e33f9c811a2ed6_5</td>\n",
       "      <td>nocall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>site_1_b2fd3f01e9284293a1e33f9c811a2ed6_10</td>\n",
       "      <td>aldfly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>site_1_b2fd3f01e9284293a1e33f9c811a2ed6_15</td>\n",
       "      <td>nocall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>site_1_b2fd3f01e9284293a1e33f9c811a2ed6_20</td>\n",
       "      <td>nocall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>site_1_b2fd3f01e9284293a1e33f9c811a2ed6_25</td>\n",
       "      <td>aldfly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>site_1_b2fd3f01e9284293a1e33f9c811a2ed6_30</td>\n",
       "      <td>nocall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>site_1_b2fd3f01e9284293a1e33f9c811a2ed6_35</td>\n",
       "      <td>nocall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>site_2_de62b37ebba749d2abf29d4a493ea5d4_5</td>\n",
       "      <td>aldfly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>site_2_8680a8dd845d40f296246dbed0d37394_5</td>\n",
       "      <td>nocall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>site_2_8680a8dd845d40f296246dbed0d37394_10</td>\n",
       "      <td>aldfly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>site_2_8680a8dd845d40f296246dbed0d37394_15</td>\n",
       "      <td>nocall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>site_2_8680a8dd845d40f296246dbed0d37394_20</td>\n",
       "      <td>aldfly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>site_2_8680a8dd845d40f296246dbed0d37394_25</td>\n",
       "      <td>aldfly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>site_2_8680a8dd845d40f296246dbed0d37394_30</td>\n",
       "      <td>aldfly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>site_2_8680a8dd845d40f296246dbed0d37394_35</td>\n",
       "      <td>aldfly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>site_2_8680a8dd845d40f296246dbed0d37394_40</td>\n",
       "      <td>aldfly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>site_2_8680a8dd845d40f296246dbed0d37394_45</td>\n",
       "      <td>nocall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>site_2_940d546e5eb745c9a74bce3f35efa1f9_5</td>\n",
       "      <td>nocall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>site_2_940d546e5eb745c9a74bce3f35efa1f9_10</td>\n",
       "      <td>aldfly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>site_2_940d546e5eb745c9a74bce3f35efa1f9_15</td>\n",
       "      <td>nocall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>site_2_940d546e5eb745c9a74bce3f35efa1f9_20</td>\n",
       "      <td>nocall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>site_2_940d546e5eb745c9a74bce3f35efa1f9_25</td>\n",
       "      <td>nocall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>site_2_940d546e5eb745c9a74bce3f35efa1f9_30</td>\n",
       "      <td>nocall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>site_2_940d546e5eb745c9a74bce3f35efa1f9_35</td>\n",
       "      <td>nocall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>site_2_940d546e5eb745c9a74bce3f35efa1f9_40</td>\n",
       "      <td>nocall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>site_2_940d546e5eb745c9a74bce3f35efa1f9_45</td>\n",
       "      <td>nocall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>site_2_940d546e5eb745c9a74bce3f35efa1f9_50</td>\n",
       "      <td>nocall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>site_2_940d546e5eb745c9a74bce3f35efa1f9_55</td>\n",
       "      <td>nocall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>site_2_940d546e5eb745c9a74bce3f35efa1f9_60</td>\n",
       "      <td>nocall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>site_2_940d546e5eb745c9a74bce3f35efa1f9_65</td>\n",
       "      <td>nocall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>site_2_940d546e5eb745c9a74bce3f35efa1f9_70</td>\n",
       "      <td>aldfly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>site_2_07ab324c602e4afab65ddbcc746c31b5_5</td>\n",
       "      <td>aldfly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>site_2_07ab324c602e4afab65ddbcc746c31b5_10</td>\n",
       "      <td>aldfly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>site_2_07ab324c602e4afab65ddbcc746c31b5_15</td>\n",
       "      <td>aldfly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>site_2_07ab324c602e4afab65ddbcc746c31b5_20</td>\n",
       "      <td>nocall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>site_2_07ab324c602e4afab65ddbcc746c31b5_25</td>\n",
       "      <td>nocall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>site_2_899616723a32409c996f6f3441646c2a_5</td>\n",
       "      <td>aldfly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>site_2_899616723a32409c996f6f3441646c2a_10</td>\n",
       "      <td>aldfly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>site_2_899616723a32409c996f6f3441646c2a_15</td>\n",
       "      <td>nocall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>site_2_899616723a32409c996f6f3441646c2a_20</td>\n",
       "      <td>aldfly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>site_2_899616723a32409c996f6f3441646c2a_25</td>\n",
       "      <td>nocall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>site_2_899616723a32409c996f6f3441646c2a_30</td>\n",
       "      <td>btnwar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>site_2_899616723a32409c996f6f3441646c2a_35</td>\n",
       "      <td>nocall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>site_2_899616723a32409c996f6f3441646c2a_40</td>\n",
       "      <td>nocall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>site_2_899616723a32409c996f6f3441646c2a_45</td>\n",
       "      <td>amerob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>site_2_899616723a32409c996f6f3441646c2a_50</td>\n",
       "      <td>nocall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>site_3_9cc5d9646f344f1bbb52640a988fe902</td>\n",
       "      <td>aldfly comyel magwar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>site_3_a56e20a518684688a9952add8a9d5213</td>\n",
       "      <td>aldfly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>site_3_96779836288745728306903d54e264dd</td>\n",
       "      <td>aldfly hamfly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>site_3_f77783ba4c6641bc918b034a18c23e53</td>\n",
       "      <td>aldfly hamfly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>site_3_856b194b097441958697c2bcd1f63982</td>\n",
       "      <td>aldfly</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        row_id                 birds\n",
       "0    site_1_41e6fe6504a34bf6846938ba78d13df1_5                aldfly\n",
       "1   site_1_41e6fe6504a34bf6846938ba78d13df1_10                aldfly\n",
       "2   site_1_41e6fe6504a34bf6846938ba78d13df1_15                aldfly\n",
       "3   site_1_41e6fe6504a34bf6846938ba78d13df1_20                nocall\n",
       "4   site_1_41e6fe6504a34bf6846938ba78d13df1_25                aldfly\n",
       "5    site_1_cce64fffafed40f2b2f3d3413ec1c4c2_5                aldfly\n",
       "6   site_1_cce64fffafed40f2b2f3d3413ec1c4c2_10                nocall\n",
       "7   site_1_cce64fffafed40f2b2f3d3413ec1c4c2_15                nocall\n",
       "8   site_1_cce64fffafed40f2b2f3d3413ec1c4c2_20                nocall\n",
       "9   site_1_cce64fffafed40f2b2f3d3413ec1c4c2_25                nocall\n",
       "10  site_1_cce64fffafed40f2b2f3d3413ec1c4c2_30                nocall\n",
       "11  site_1_cce64fffafed40f2b2f3d3413ec1c4c2_35                aldfly\n",
       "12   site_1_99af324c881246949408c0b1ae54271f_5                nocall\n",
       "13  site_1_99af324c881246949408c0b1ae54271f_10                aldfly\n",
       "14  site_1_99af324c881246949408c0b1ae54271f_15                nocall\n",
       "15  site_1_99af324c881246949408c0b1ae54271f_20                aldfly\n",
       "16  site_1_99af324c881246949408c0b1ae54271f_25                aldfly\n",
       "17  site_1_99af324c881246949408c0b1ae54271f_30                aldfly\n",
       "18  site_1_99af324c881246949408c0b1ae54271f_35                aldfly\n",
       "19   site_1_6ab74e177aa149468a39ca10beed6222_5                aldfly\n",
       "20  site_1_6ab74e177aa149468a39ca10beed6222_10                aldfly\n",
       "21  site_1_6ab74e177aa149468a39ca10beed6222_15                aldfly\n",
       "22  site_1_6ab74e177aa149468a39ca10beed6222_20                aldfly\n",
       "23  site_1_6ab74e177aa149468a39ca10beed6222_25                aldfly\n",
       "24  site_1_6ab74e177aa149468a39ca10beed6222_30                nocall\n",
       "25   site_1_b2fd3f01e9284293a1e33f9c811a2ed6_5                nocall\n",
       "26  site_1_b2fd3f01e9284293a1e33f9c811a2ed6_10                aldfly\n",
       "27  site_1_b2fd3f01e9284293a1e33f9c811a2ed6_15                nocall\n",
       "28  site_1_b2fd3f01e9284293a1e33f9c811a2ed6_20                nocall\n",
       "29  site_1_b2fd3f01e9284293a1e33f9c811a2ed6_25                aldfly\n",
       "30  site_1_b2fd3f01e9284293a1e33f9c811a2ed6_30                nocall\n",
       "31  site_1_b2fd3f01e9284293a1e33f9c811a2ed6_35                nocall\n",
       "32   site_2_de62b37ebba749d2abf29d4a493ea5d4_5                aldfly\n",
       "33   site_2_8680a8dd845d40f296246dbed0d37394_5                nocall\n",
       "34  site_2_8680a8dd845d40f296246dbed0d37394_10                aldfly\n",
       "35  site_2_8680a8dd845d40f296246dbed0d37394_15                nocall\n",
       "36  site_2_8680a8dd845d40f296246dbed0d37394_20                aldfly\n",
       "37  site_2_8680a8dd845d40f296246dbed0d37394_25                aldfly\n",
       "38  site_2_8680a8dd845d40f296246dbed0d37394_30                aldfly\n",
       "39  site_2_8680a8dd845d40f296246dbed0d37394_35                aldfly\n",
       "40  site_2_8680a8dd845d40f296246dbed0d37394_40                aldfly\n",
       "41  site_2_8680a8dd845d40f296246dbed0d37394_45                nocall\n",
       "42   site_2_940d546e5eb745c9a74bce3f35efa1f9_5                nocall\n",
       "43  site_2_940d546e5eb745c9a74bce3f35efa1f9_10                aldfly\n",
       "44  site_2_940d546e5eb745c9a74bce3f35efa1f9_15                nocall\n",
       "45  site_2_940d546e5eb745c9a74bce3f35efa1f9_20                nocall\n",
       "46  site_2_940d546e5eb745c9a74bce3f35efa1f9_25                nocall\n",
       "47  site_2_940d546e5eb745c9a74bce3f35efa1f9_30                nocall\n",
       "48  site_2_940d546e5eb745c9a74bce3f35efa1f9_35                nocall\n",
       "49  site_2_940d546e5eb745c9a74bce3f35efa1f9_40                nocall\n",
       "50  site_2_940d546e5eb745c9a74bce3f35efa1f9_45                nocall\n",
       "51  site_2_940d546e5eb745c9a74bce3f35efa1f9_50                nocall\n",
       "52  site_2_940d546e5eb745c9a74bce3f35efa1f9_55                nocall\n",
       "53  site_2_940d546e5eb745c9a74bce3f35efa1f9_60                nocall\n",
       "54  site_2_940d546e5eb745c9a74bce3f35efa1f9_65                nocall\n",
       "55  site_2_940d546e5eb745c9a74bce3f35efa1f9_70                aldfly\n",
       "56   site_2_07ab324c602e4afab65ddbcc746c31b5_5                aldfly\n",
       "57  site_2_07ab324c602e4afab65ddbcc746c31b5_10                aldfly\n",
       "58  site_2_07ab324c602e4afab65ddbcc746c31b5_15                aldfly\n",
       "59  site_2_07ab324c602e4afab65ddbcc746c31b5_20                nocall\n",
       "60  site_2_07ab324c602e4afab65ddbcc746c31b5_25                nocall\n",
       "61   site_2_899616723a32409c996f6f3441646c2a_5                aldfly\n",
       "62  site_2_899616723a32409c996f6f3441646c2a_10                aldfly\n",
       "63  site_2_899616723a32409c996f6f3441646c2a_15                nocall\n",
       "64  site_2_899616723a32409c996f6f3441646c2a_20                aldfly\n",
       "65  site_2_899616723a32409c996f6f3441646c2a_25                nocall\n",
       "66  site_2_899616723a32409c996f6f3441646c2a_30                btnwar\n",
       "67  site_2_899616723a32409c996f6f3441646c2a_35                nocall\n",
       "68  site_2_899616723a32409c996f6f3441646c2a_40                nocall\n",
       "69  site_2_899616723a32409c996f6f3441646c2a_45                amerob\n",
       "70  site_2_899616723a32409c996f6f3441646c2a_50                nocall\n",
       "71     site_3_9cc5d9646f344f1bbb52640a988fe902  aldfly comyel magwar\n",
       "72     site_3_a56e20a518684688a9952add8a9d5213                aldfly\n",
       "73     site_3_96779836288745728306903d54e264dd         aldfly hamfly\n",
       "74     site_3_f77783ba4c6641bc918b034a18c23e53         aldfly hamfly\n",
       "75     site_3_856b194b097441958697c2bcd1f63982                aldfly"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-15T19:25:44.824862Z",
     "iopub.status.busy": "2020-09-15T19:25:44.824023Z",
     "iopub.status.idle": "2020-09-15T19:25:44.828006Z",
     "shell.execute_reply": "2020-09-15T19:25:44.827537Z"
    },
    "papermill": {
     "duration": 0.06421,
     "end_time": "2020-09-15T19:25:44.828101",
     "exception": false,
     "start_time": "2020-09-15T19:25:44.763891",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nocall                  36\n",
       "aldfly                  35\n",
       "aldfly hamfly            2\n",
       "amerob                   1\n",
       "btnwar                   1\n",
       "aldfly comyel magwar     1\n",
       "Name: birds, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission['birds'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-15T19:25:44.942419Z",
     "iopub.status.busy": "2020-09-15T19:25:44.941479Z",
     "iopub.status.idle": "2020-09-15T19:25:44.944840Z",
     "shell.execute_reply": "2020-09-15T19:25:44.944269Z"
    },
    "papermill": {
     "duration": 0.062986,
     "end_time": "2020-09-15T19:25:44.944959",
     "exception": false,
     "start_time": "2020-09-15T19:25:44.881973",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# nocall           47\n",
    "# aldfly           24\n",
    "# amerob            1\n",
    "# sonspa            1\n",
    "# aldfly comyel     1\n",
    "# astfly            1\n",
    "# wesgre            1\n",
    "# Name: birds, dtype: int64\n",
    "# threshold 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.05775,
     "end_time": "2020-09-15T19:25:45.066301",
     "exception": false,
     "start_time": "2020-09-15T19:25:45.008551",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 138.841352,
   "end_time": "2020-09-15T19:25:46.587874",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-09-15T19:23:27.746522",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
